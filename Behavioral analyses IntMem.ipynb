{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Behavioral analyses IntMem - MvK 2017\n",
    "\n",
    "# Read in necessary stuff\n",
    "#%pylab inline\n",
    "from ipykernel import kernelapp as app\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "#import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "#import pylab as pl\n",
    "import seaborn as sns\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2293ab08c331>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# read in recall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Object'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Congruency'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Empty'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Recognition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Confidence'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pic desc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RT.1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pic rec'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Confidence2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RT2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     df = pd.read_csv('C:/Users/mkn556/Documents/Research/Projects/IntMem/VU/logfiles/s%i/s%i_recall1.txt' % (s,s), sep = '\\t', \n\u001b[0m\u001b[0;32m     11\u001b[0m                      header = None, names = names, skiprows = 4, skipfooter = 3, engine = 'python')\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Read in logfile for recall\n",
    "subjects = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,22,23,24,25,26,27,28,29,30] #fMRI batch\n",
    "\n",
    "#subjects = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]\n",
    "for s in subjects: \n",
    "    \n",
    "    #print('Running subject s%i' %s)\n",
    "    # read in recall\n",
    "    names = ['Object', 'Congruency', 'Empty', 'Recognition', 'Confidence', 'RT', 'Pic desc', 'RT.1', 'Pic rec', 'Confidence2', 'RT2']\n",
    "    df = pd.read_csv('C:/Users/mkn556/Documents/Research/Projects/IntMem/VU/logfiles/s%i/s%i_recall1.txt' % (s,s), sep = '\\t', \n",
    "                     header = None, names = names, skiprows = 4, skipfooter = 3, engine = 'python')\n",
    "\n",
    "    # for s4: missed items (because this participant had a technical issue)\n",
    "    if s == 4: \n",
    "        s4_missed_items = pd.read_excel('C:/Users/mkn556/Documents/Research/Projects/IntMem/VU/logfiles/s4/missed_items.xlsx',\n",
    "                     header = None, names = names)   \n",
    "        print(df)\n",
    "        df = pd.merge(df, s4_missed_items)#, how = 'outer')\n",
    "\n",
    "    # delete second column (accidental space) and RT1 (not useful)\n",
    "    columns = ['Empty', 'RT.1']\n",
    "    df = df.drop(columns, axis = 1)\n",
    "\n",
    "    # select only learned items and sort by object name, store in all_data    \n",
    "    all_data = df[(df.Congruency == 'con') | (df.Congruency == 'inc')]\n",
    "    all_data = all_data.sort_values(by = ['Object'])\n",
    "    all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "    # create separate df with misses and no responses and change format to fit pic desc excels (which don't contain misses)\n",
    "    miss_nr = all_data[(all_data.Recognition != 'Hit')]\n",
    "    columns = ['Congruency', 'Recognition', 'Confidence', 'RT', 'Pic rec', 'Confidence2', 'RT2']\n",
    "    miss_nr = miss_nr.drop(columns, axis = 1)\n",
    "    miss_nr['Points'] = 0 \n",
    "    miss_nr['FM_con'] = 0 \n",
    "    miss_nr['FM_inc'] = 0\n",
    "\n",
    "    # read in ratings for picture description and merge with recall_miss_nr so it can be merged with all_data\n",
    "    xls = pd.ExcelFile('C:/Users/mkn556/Documents/Research/Projects/IntMem/VU/logfiles/s%i/s%i_picture_recall1_rater1.xlsx' % (s,s))\n",
    "    con = xls.parse(0)\n",
    "    inc = xls.parse(1)\n",
    "    picdesc_rater1 = pd.merge(con,inc, how = 'outer')\n",
    "    xls = pd.ExcelFile('C:/Users/mkn556/Documents/Research/Projects/IntMem/VU/logfiles/s%i/s%i_picture_recall1_rater2.xlsx' % (s,s))\n",
    "    con = xls.parse(0)\n",
    "    inc = xls.parse(1)\n",
    "    picdesc_rater2 = pd.merge(con,inc, how = 'outer')\n",
    "\n",
    "    picdesc = picdesc_rater1\n",
    "    picdesc['Points'] = (picdesc_rater1['Punten'] + picdesc_rater2['Punten'])/2\n",
    "    picdesc['FM_con'] = (picdesc_rater1['FM con'] + picdesc_rater2['FM con'])/2\n",
    "    picdesc['FM_inc'] = (picdesc_rater1['FM inc'] + picdesc_rater2['FM incon'])/2 # note that rater 2 used a different column name\n",
    "    columns = ['Punten', 'FM con', 'FM inc']\n",
    "    picdesc = picdesc.drop(columns, axis = 1)\n",
    "    picdesc = pd.merge(picdesc, miss_nr, how = 'outer')\n",
    "    picdesc = picdesc.sort_values(by = ['Object'])\n",
    "    picdesc = picdesc.reset_index(drop=True)\n",
    "\n",
    "    # add ratings to recall_learned\n",
    "    all_data[['Points', 'FM_con', 'FM_inc']] = picdesc[['Points','FM_con','FM_inc']]\n",
    "    all_data.Points = all_data.Points.astype(int)\n",
    "    all_data.FM_con = all_data.FM_con.astype(int)\n",
    "    all_data.FM_inc = all_data.FM_inc.astype(int)\n",
    "    all_data = all_data[['Object','Congruency','Recognition','Confidence','RT','Pic desc','Points','FM_con','FM_inc',\n",
    "                                   'Pic rec', 'Confidence2','RT2']] # reorder columns\n",
    "\n",
    "    # read in congruency ratings\n",
    "    con_ratings = pd.read_csv('C:/Users/mkn556/Documents/Research/Projects/IntMem/VU/logfiles/s%i/s%i_con.txt' % (s,s), sep = '\\t', \n",
    "                     header = 1, skipfooter = 2, engine = 'python')\n",
    "    con_ratings = con_ratings.sort_values(by = ['Scene']) # note here that the column names in the logfiles are inverted (i.e. object = scene and v.v.)\n",
    "    con_ratings = con_ratings.reset_index(drop=True)\n",
    "    all_data['Con_rating'] = con_ratings['Answer']\n",
    "    all_data.Con_rating = all_data.Con_rating.astype(int)\n",
    "    all_data['Con_subj'] = 'test'\n",
    "    all_data['Con_subj']\n",
    "\n",
    "    # add row with subjective \"con\" and \"inc (or N/A in case of a \"3\" answer) for further analyses\n",
    "    def congruency(row):\n",
    "        if row['Con_rating'] < 3: # less than 3 = inc\n",
    "            return 'inc'\n",
    "        elif 3 < row['Con_rating'] < 6: # more than 3 and less than 6 (Enter) = con\n",
    "            return 'con'\n",
    "        else:\n",
    "            return 'N/A' # answered 3 (no congruency) or 6 (Enter)\n",
    "\n",
    "    all_data['Con_subj'] = all_data.apply (lambda row: congruency (row),axis=1)\n",
    "\n",
    "    # read in AC-encoding\n",
    "    ACencoding = pd.read_csv('C:/Users/mkn556/Documents/Research/Projects/IntMem/VU/logfiles/s%i/s%i_ACencoding.txt' % (s,s), sep = '\\t', \n",
    "                         header = 4, skipfooter = 3, engine = 'python')\n",
    "\n",
    "    # delete some rows with header information, reset index, and sort\n",
    "    ACencoding.drop(ACencoding.index[[0,65,66,67,68,69,70,127]], inplace=True)\n",
    "\n",
    "    # assign Run numbers to df and sort\n",
    "    run = np.concatenate((np.ones(64, dtype=np.int),np.ones(56, dtype=np.int)*2),axis = 0)\n",
    "    ACencoding['Run'] = run\n",
    "    ACencoding = ACencoding.sort_values(by = ['Object'])\n",
    "    ACencoding = ACencoding.reset_index(drop=True)\n",
    "\n",
    "    # move columns Reactivation, RT and onset to recall df\n",
    "    all_data[['Reactivation','RT_enc','Onset','Run']] = ACencoding[['Reactivation','RT','Onset','Run']]\n",
    "    all_data.Reactivation = all_data.Reactivation.astype(int)\n",
    "    all_data.RT_enc = all_data.RT_enc.astype(int)\n",
    "    all_data.Onset = all_data.Onset.astype(int)\n",
    "    all_data.Run = all_data.Run.astype(int)\n",
    "    \n",
    "    # change Reactivation \"4\" scores (no answer) to \"NaN\"\n",
    "    all_data.loc[all_data.Reactivation==4, ['Reactivation', 'RT_enc']]= np.nan\n",
    "\n",
    "    # copy No responses and delete from df so we can do analyses on remaining trials but put these back later\n",
    "    NRs = all_data[all_data.Recognition == 'No response'] \n",
    "    all_data = all_data[all_data.Recognition != 'No response'] \n",
    "    all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "    # Calculate memory score and add to df all_data\n",
    "    memory_scores = []\n",
    "    for i in range(0,len(all_data)):\n",
    "        memory_score = 0\n",
    "        if all_data['Recognition'][i] == 'Hit': # Recognition score\n",
    "            memory_score = memory_score + (4-all_data['Confidence'][i])\n",
    "        if all_data['Pic rec'][i] == 'Hit': # Picture recognition score, confidence randomized\n",
    "            if all_data['Confidence2'][i] > 3.0:\n",
    "                memory_score = memory_score + (all_data['Confidence2'][i] - 3) # 6 is highest\n",
    "            else:\n",
    "                memory_score = memory_score + (4 - all_data['Confidence2'][i]) # 1 is highest\n",
    "\n",
    "        memory_score = memory_score + all_data['Points'][i]*3\n",
    "        memory_scores.append(memory_score)\n",
    "\n",
    "    #add memory scores to df all_data\n",
    "    all_data['Memory_score'] = memory_scores\n",
    "    all_data.Memory_score = all_data.Memory_score.astype(int)\n",
    "\n",
    "    # delete rows for s4 again (those that were not answered during recall)\n",
    "    if s == 4:\n",
    "        all_data = all_data[~all_data['Object'].isin(s4_missed_items['Object'])]\n",
    "        all_data = all_data.reset_index(drop=True)\n",
    "        \n",
    "    # end for loop, now final dataframe is read in and analyses can be done\n",
    "    all_data = all_data[(all_data.Recognition == 'Hit')] # FOR FA ANALYSES\n",
    "    all_data = all_data.reset_index(drop=True) # FOR FA ANALYSES \n",
    "    means = all_data.groupby('Con_subj')['Memory_score', 'Reactivation', 'RT_enc', 'FM_con', 'FM_inc'].mean() # calculate means\n",
    "    median_MS = all_data.groupby('Con_subj')['Memory_score'].median() # calculate median for median split\n",
    "    trials_hit_con = all_data.groupby('Con_subj')['Memory_score'].apply(lambda column: sum(column >= means['Memory_score'].con)) # calculate amount of trials\n",
    "    trials_miss_con = all_data.groupby('Con_subj')['Memory_score'].apply(lambda column: sum(column < means['Memory_score'].con)) # calculate amount of trials \n",
    "    trials_hit_inc = all_data.groupby('Con_subj')['Memory_score'].apply(lambda column: sum(column >= means['Memory_score'].inc)) # calculate amount of trials\n",
    "    trials_miss_inc = all_data.groupby('Con_subj')['Memory_score'].apply(lambda column: sum(column < means['Memory_score'].inc)) # calculate amount of trials\n",
    "    \n",
    "    print(means)\n",
    "    #test_df = all_data[all_data['Memory_score']>0]\n",
    "    #trials_reac = test_df.groupby('Con_subj')['Reactivation'].apply(lambda column: sum(column > 0)) # calculate amount of trials based on reactivation score\n",
    "        \n",
    "    if s == 1: # start dataframes with groupdata\n",
    "        final_df = pd.DataFrame(columns = ['MS_con', 'MS_inc', 'MR_con', 'MR_inc','sum_con', 'sum_inc', 'trials_hit_con', \n",
    "                                           'trials_hit_inc', 'trials_miss_con', 'trials_miss_con', 'RT_con', 'RT_inc', \n",
    "                                           'FM_con_con','FM_con_inc','FM_inc_con','FM_inc_inc'])\n",
    "        graph_df = all_data.groupby(['Con_subj','Reactivation'])['Points'].mean()\n",
    "        graph_df = graph_df.to_frame() \n",
    "        graph_df = graph_df.reset_index() \n",
    "\n",
    "    # fill dfs with subject-specific information\n",
    "    final_df.loc['s%i' %s] = [means['Memory_score'].con,means['Memory_score'].inc,means['Reactivation'].con,\n",
    "                              means['Reactivation'].inc, sum(all_data.Con_subj == 'con'), sum(all_data.Con_subj == 'inc'),\n",
    "                              trials_hit_con.con,trials_hit_inc.inc, trials_miss_con.con, trials_miss_inc.inc, means['RT_enc'].con,\n",
    "                              means['RT_enc'].inc, means['FM_con'].con, means['FM_inc'].con, means['FM_con'].inc, means['FM_inc'].inc]\n",
    "    if s != 1: \n",
    "        graph_df2 = all_data.groupby(['Con_subj','Reactivation'])['Points'].mean()\n",
    "        graph_df2 = graph_df2.to_frame()    \n",
    "        graph_df2 = graph_df2.reset_index() \n",
    "        graph_df = graph_df.append(graph_df2,ignore_index=True)\n",
    "    \n",
    "    # add not responses back to all_data DF and save for further analyses\n",
    "    all_data = all_data.append(NRs)\n",
    "    #all_data.to_excel('Z:/IntMem/data/s%i/logfiles/DF_s%i.xlsx' %(s,s))\n",
    "    print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final group outcomes\n",
    "graph_df = graph_df[graph_df.Con_subj!= 'N/A']\n",
    "graph_df.Reactivation = graph_df.Reactivation.astype(int)\n",
    "graph_df = graph_df.rename(columns={'Con_subj': 'Congruency'})\n",
    "graph_df = graph_df.replace(to_replace='con', value='Congruent')\n",
    "graph_df = graph_df.replace(to_replace='inc', value='Incongruent')\n",
    "#graph_df['Points'] = graph_df['Points']*100\n",
    "graph_df\n",
    "#graph_df.to_excel('C:/Users/mkn556/Dropbox/Research/Running projects/IntMem/VU/analyses/congruencyxreactivation_assmemory.xlsx')\n",
    "\n",
    "# make graph and save\n",
    "sns.set(style=\"ticks\", font_scale = 2)\n",
    "g2 = sns.factorplot(x=\"Reactivation\", y=\"Memory_score\", hue=\"Congruency\", data=graph_df, ci = 48.47,\n",
    "       capsize=0, palette=\"hot\", size=9, aspect=1.2, dodge = .3, legend = False, legend_out = False)\n",
    "sns.stripplot(x=\"Reactivation\", y=\"Memory_score\", hue=\"Congruency\", data=graph_df, jitter = True,\n",
    "       palette=\"hot\")\n",
    "g2.set(ylim=(-5, 85))\n",
    "g2.set_ylabels(\"Associative memory (%)\")\n",
    "g2.set_xticklabels([\"Strong\", \"A bit\", \"None\"])\n",
    "g2.add_legend()\n",
    "\n",
    "#savefig(\"C:/Users/mkn556/Dropbox/Research/Conferences & Workshops/NVP 2017/fMRI_fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
